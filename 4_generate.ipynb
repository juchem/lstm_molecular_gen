{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate\n",
    "\n",
    "Load trained weights, synthesize new sequences, save SMILES to a plain text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "from smiles.smiles_tokenizer import SmilesTokenizer\n",
    "from smiles.smiles_utils import cleanup_list_smiles, encode_list_smiles\n",
    "\n",
    "from model.lstm_model import build_model\n",
    "\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model and load trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SmilesTokenizer()\n",
    "vocab_size = st.table_len\n",
    "\n",
    "model = build_model(vocab_size, 128, .1, 'nadam')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.load_weights('saved_models/model_nadam_128_100epochs_1000batch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('tmp/smiles_train.npy')\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, :-1]\n",
    "labels = dataset[:, -1:]\n",
    "y = tf.keras.utils.to_categorical(labels, num_classes=vocab_size)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('int')\n",
    "y = tf.argmax(y, axis=1).numpy().astype('int')\n",
    "y_pred = tf.argmax(y_pred, axis=1).numpy().astype('int')\n",
    "\n",
    "print(X.shape)\n",
    "print(labels.shape)\n",
    "print(y.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesize sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = []\n",
    "for i in range(len(X)):\n",
    "    s = st.embeddings_to_smiles(X[i]) + st.embeddings_to_smiles(y[i])\n",
    "    smiles.append(s)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    s = st.embeddings_to_smiles(X[i]) + st.embeddings_to_smiles(y_pred[i])\n",
    "    smiles.append(s)\n",
    "\n",
    "smiles = list(set(smiles))\n",
    "\n",
    "valid_smiles = cleanup_list_smiles(smiles)\n",
    "\n",
    "#print(valid_smiles)\n",
    "\n",
    "print('Generated:', len(smiles))\n",
    "print('Valid:', len(valid_smiles))\n",
    "        \n",
    "with open('tmp/valid_smiles.smi', 'w') as f:\n",
    "    for s in valid_smiles:\n",
    "        f.write(\"%s\\n\" % s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
